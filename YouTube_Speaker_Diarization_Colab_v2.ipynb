{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Speaker Diarization (Colab v2, faster-whisper)\n",
    "\n",
    "- 带依赖缓存（`/content/cache`）\n",
    "- 重启后可跳过重复下载依赖\n",
    "- 支持可选双GPU并行（多任务场景）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 一键初始化（带缓存）\n",
    "首次会下载并缓存 wheel；后续重启可跳过安装。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL = 'https://github.com/Hana19951208/youtube-speaker-diarization.git'\n",
    "REPO_DIR = '/content/youtube-speaker-diarization'\n",
    "CACHE_DIR = Path('/content/cache')\n",
    "WHEELHOUSE = CACHE_DIR / 'wheelhouse'\n",
    "STAMP = CACHE_DIR / 'deps_installed_colab_v2.flag'\n",
    "\n",
    "!apt-get update -y\n",
    "!apt-get install -y ffmpeg\n",
    "\n",
    "%cd /content\n",
    "if os.path.exists(REPO_DIR):\n",
    "    !rm -rf {REPO_DIR}\n",
    "!git clone {REPO_URL}\n",
    "%cd {REPO_DIR}\n",
    "\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "WHEELHOUSE.mkdir(parents=True, exist_ok=True)\n",
    "os.environ['PIP_CACHE_DIR'] = str(CACHE_DIR / 'pip')\n",
    "os.environ['HF_HOME'] = str(CACHE_DIR / 'huggingface')\n",
    "os.environ['HF_HUB_CACHE'] = str(CACHE_DIR / 'huggingface' / 'hub')\n",
    "os.environ['TORCH_HOME'] = str(CACHE_DIR / 'torch')\n",
    "\n",
    "if STAMP.exists():\n",
    "    print('✅ 检测到缓存标记，跳过依赖安装。')\n",
    "else:\n",
    "    print('⏬ 首次安装：下载并缓存 wheels ...')\n",
    "    !pip download -q -r requirements.txt -d {WHEELHOUSE}\n",
    "    !pip download -q torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 -d {WHEELHOUSE}\n",
    "\n",
    "    !pip uninstall -y whisperx faster-whisper pyannote.audio transformers accelerate numpy pandas torch torchvision torchaudio -q\n",
    "    !pip install -q --no-index --find-links {WHEELHOUSE} torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1\n",
    "    !pip install -q --no-index --find-links {WHEELHOUSE} -r requirements.txt\n",
    "    STAMP.write_text('ok')\n",
    "    print('✅ 依赖安装完成并已缓存。')\n",
    "\n",
    "print('⚠️ 建议现在 Runtime -> Restart runtime，然后从 1.1 继续。')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) 重启后健康检查\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy, pandas, transformers, accelerate, yt_dlp\n",
    "from faster_whisper import WhisperModel\n",
    "print('torch:', torch.__version__)\n",
    "print('transformers:', transformers.__version__)\n",
    "print('accelerate:', accelerate.__version__)\n",
    "print('numpy:', numpy.__version__)\n",
    "print('pandas:', pandas.__version__)\n",
    "print('yt-dlp:', yt_dlp.version.__version__)\n",
    "print('cuda available:', torch.cuda.is_available())\n",
    "print('gpu count:', torch.cuda.device_count())\n",
    "_ = WhisperModel('tiny', device='cpu', compute_type='int8')\n",
    "print('✅ import check passed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 设置 HF_TOKEN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_TOKEN = ''  # 可直接填；或在 Colab Secrets/环境变量里设置\n",
    "import os\n",
    "if not HF_TOKEN:\n",
    "    HF_TOKEN = os.environ.get('HF_TOKEN', '')\n",
    "os.environ['HF_TOKEN'] = HF_TOKEN\n",
    "print('HF_TOKEN set:', bool(HF_TOKEN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 上传参考音频\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "ref_audio_path = None\n",
    "if uploaded:\n",
    "    ref_audio_path = '/content/' + next(iter(uploaded.keys()))\n",
    "print('ref_audio_path =', ref_audio_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 配置参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'youtube_url': 'https://www.youtube.com/watch?v=Zs8jUFaqtCI',\n",
    "    'playlist_mode': 'single',\n",
    "    'language': 'zh',\n",
    "    'max_speakers': 3,\n",
    "    'whisper_model': 'large-v3',\n",
    "    'do_separation': False,\n",
    "    'do_vad': False,\n",
    "    'do_enhance': False,\n",
    "    'similarity_threshold': 0.25,\n",
    "    'output_dir': './output',\n",
    "    'enable_dual_gpu_multi_task': True,\n",
    "}\n",
    "CONFIG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5) Step5前同步最新代码 + 补齐依赖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/youtube-speaker-diarization\n",
    "!git fetch origin\n",
    "!git pull --rebase origin master || git pull origin master\n",
    "!pip install -q -r requirements.txt\n",
    "print('✅ synced')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 单视频运行（默认）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import YouTubeSpeakerPipeline\n",
    "pipeline = YouTubeSpeakerPipeline(\n",
    "    hf_token=HF_TOKEN,\n",
    "    output_dir=CONFIG['output_dir'],\n",
    "    whisper_model=CONFIG['whisper_model'],\n",
    "    max_speakers=CONFIG['max_speakers'],\n",
    "    do_separation=CONFIG['do_separation'],\n",
    "    do_vad=CONFIG['do_vad'],\n",
    "    do_enhance=CONFIG['do_enhance'],\n",
    "    similarity_threshold=CONFIG['similarity_threshold'],\n",
    "    playlist_mode=CONFIG['playlist_mode'],\n",
    ")\n",
    "results = pipeline.process(\n",
    "    youtube_url=CONFIG['youtube_url'],\n",
    "    ref_audio_path=ref_audio_path,\n",
    "    language=CONFIG['language'],\n",
    ")\n",
    "print('✅ done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) 双GPU并行（可选，多任务时有效）\n",
    "说明：单个视频的同一条流水线很难高效吃满2块GPU。\n",
    "这个cell用于**多个URL并行**，每个进程绑定一张GPU。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, torch\n",
    "URLS = []  # 例如填2个视频链接，才能明显利用2块GPU\n",
    "if torch.cuda.device_count() < 2:\n",
    "    print('当前不足2块GPU，跳过')\n",
    "elif not URLS:\n",
    "    print('请先填 URLS 再运行')\n",
    "else:\n",
    "    procs=[]\n",
    "    for i,u in enumerate(URLS):\n",
    "        gpu=i%2\n",
    "        env=os.environ.copy()\n",
    "        env['CUDA_VISIBLE_DEVICES']=str(gpu)\n",
    "        cmd=[\n",
    "          'python','main.py',\n",
    "          '--youtube_url',u,\n",
    "          '--ref_audio',ref_audio_path,\n",
    "          '--output_dir',f'./output_gpu{gpu}_{i}',\n",
    "          '--language',CONFIG['language'],\n",
    "          '--max_speakers',str(CONFIG['max_speakers']),\n",
    "          '--whisper_model',CONFIG['whisper_model'],\n",
    "          '--playlist_mode',CONFIG['playlist_mode'],\n",
    "          '--no_separation'\n",
    "        ]\n",
    "        procs.append(subprocess.Popen(cmd, env=env))\n",
    "    for p in procs:\n",
    "        p.wait()\n",
    "    print('✅ dual-gpu batch done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 查看输出\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "for f in sorted(glob.glob('./output/*.srt') + glob.glob('./output/*.json')):\n",
    "    print('-', f)\n"
   ]
  }
 ]
}