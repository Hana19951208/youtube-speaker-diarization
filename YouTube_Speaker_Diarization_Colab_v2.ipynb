{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lutwVk5KW6jY"
      },
      "source": [
        "# YouTube Speaker Diarization (Colab v2, faster-whisper)\n",
        "\n",
        "- 带依赖缓存（`/content/cache`）\n",
        "- 重启后可跳过重复下载依赖\n",
        "- 支持可选双GPU并行（多任务场景）\n"
      ],
      "id": "lutwVk5KW6jY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tH5AUZNqW6jZ"
      },
      "source": [
        "## 1) 一键初始化（带缓存）\n",
        "首次会下载并缓存 wheel；后续重启可跳过安装。\n"
      ],
      "id": "tH5AUZNqW6jZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcxcXgR_W6ja"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "REPO_URL = 'https://github.com/Hana19951208/youtube-speaker-diarization.git'\n",
        "REPO_DIR = '/content/youtube-speaker-diarization'\n",
        "CACHE_DIR = Path('/content/cache')\n",
        "WHEELHOUSE = CACHE_DIR / 'wheelhouse'\n",
        "STAMP = CACHE_DIR / 'deps_installed_colab_v2.flag'\n",
        "\n",
        "!apt-get update -y\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "%cd /content\n",
        "if os.path.exists(REPO_DIR):\n",
        "    !rm -rf {REPO_DIR}\n",
        "!git clone {REPO_URL}\n",
        "%cd {REPO_DIR}\n",
        "\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "WHEELHOUSE.mkdir(parents=True, exist_ok=True)\n",
        "os.environ['PIP_CACHE_DIR'] = str(CACHE_DIR / 'pip')\n",
        "os.environ['HF_HOME'] = str(CACHE_DIR / 'huggingface')\n",
        "os.environ['HF_HUB_CACHE'] = str(CACHE_DIR / 'huggingface' / 'hub')\n",
        "os.environ['TORCH_HOME'] = str(CACHE_DIR / 'torch')\n",
        "\n",
        "if STAMP.exists():\n",
        "    print('✅ 检测到缓存标记，跳过依赖安装。')\n",
        "else:\n",
        "    print('⏬ 首次安装：下载并缓存 wheels ...')\n",
        "    !pip download -q -r requirements.txt -d {WHEELHOUSE}\n",
        "    !pip download -q torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 -d {WHEELHOUSE}\n",
        "\n",
        "    !pip uninstall -y whisperx faster-whisper pyannote.audio transformers accelerate numpy pandas torch torchvision torchaudio -q\n",
        "    !pip install -q --no-index --find-links {WHEELHOUSE} torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1\n",
        "    !pip install -q --no-index --find-links {WHEELHOUSE} -r requirements.txt\n",
        "    STAMP.write_text('ok')\n",
        "    print('✅ 依赖安装完成并已缓存。')\n",
        "\n",
        "print('⚠️ 建议现在 Runtime -> Restart runtime，然后从 1.1 继续。')\n"
      ],
      "id": "LcxcXgR_W6ja"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8J_DircfW6ja"
      },
      "source": [
        "## 1.1) 重启后健康检查\n"
      ],
      "id": "8J_DircfW6ja"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVTQb-aDW6jb"
      },
      "outputs": [],
      "source": [
        "import torch, numpy, pandas, transformers, accelerate, yt_dlp\n",
        "from faster_whisper import WhisperModel\n",
        "print('torch:', torch.__version__)\n",
        "print('transformers:', transformers.__version__)\n",
        "print('accelerate:', accelerate.__version__)\n",
        "print('numpy:', numpy.__version__)\n",
        "print('pandas:', pandas.__version__)\n",
        "print('yt-dlp:', yt_dlp.version.__version__)\n",
        "print('cuda available:', torch.cuda.is_available())\n",
        "print('gpu count:', torch.cuda.device_count())\n",
        "_ = WhisperModel('tiny', device='cpu', compute_type='int8')\n",
        "print('✅ import check passed')\n"
      ],
      "id": "kVTQb-aDW6jb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gco3vblW6jb"
      },
      "source": [
        "## 2) 设置 HF_TOKEN\n"
      ],
      "id": "5Gco3vblW6jb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwrjEoOzW6jb"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN', '')\n",
        "print('HF_TOKEN set:', bool(HF_TOKEN))\n"
      ],
      "id": "JwrjEoOzW6jb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-LhDhFFW6jb"
      },
      "source": [
        "## 3) 上传参考音频\n"
      ],
      "id": "6-LhDhFFW6jb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yHXK5t0W6jc"
      },
      "outputs": [],
      "source": [
        "ref_audio_path = '/content/youtube-speaker-diarization/biao.mp3'\n",
        "\n",
        "print('ref_audio_path =', ref_audio_path)\n"
      ],
      "id": "-yHXK5t0W6jc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtVjeA_mW6jc"
      },
      "source": [
        "## 4) 配置参数\n"
      ],
      "id": "NtVjeA_mW6jc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXQqjiDHW6jc"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\n",
        "    'youtube_url': 'https://www.youtube.com/watch?v=Zs8jUFaqtCI',\n",
        "    'playlist_mode': 'single',\n",
        "    'language': 'zh',\n",
        "    'max_speakers': 3,\n",
        "    'whisper_model': 'large-v3',\n",
        "    'do_separation': False,\n",
        "    'do_vad': False,\n",
        "    'do_enhance': False,\n",
        "    'similarity_threshold': 0.25,\n",
        "    'output_dir': './output',\n",
        "    'enable_dual_gpu_multi_task': True,\n",
        "}\n",
        "CONFIG\n"
      ],
      "id": "oXQqjiDHW6jc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w85uLnwVW6jc"
      },
      "source": [
        "## 4.5) Step5前同步最新代码 + 补齐依赖\n"
      ],
      "id": "w85uLnwVW6jc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh5BakTlW6jc"
      },
      "outputs": [],
      "source": [
        "%cd /content/youtube-speaker-diarization\n",
        "!git fetch origin\n",
        "!git pull --rebase origin master || git pull origin master\n",
        "print('✅ synced')\n"
      ],
      "id": "Wh5BakTlW6jc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3vA_LqGW6jd"
      },
      "source": [
        "## 5) 单视频运行（默认）\n"
      ],
      "id": "O3vA_LqGW6jd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npU3D1uwW6jd"
      },
      "outputs": [],
      "source": [
        "from pipeline import YouTubeSpeakerPipeline\n",
        "pipeline = YouTubeSpeakerPipeline(\n",
        "    hf_token=HF_TOKEN,\n",
        "    output_dir=CONFIG['output_dir'],\n",
        "    whisper_model=CONFIG['whisper_model'],\n",
        "    max_speakers=CONFIG['max_speakers'],\n",
        "    do_separation=CONFIG['do_separation'],\n",
        "    do_vad=CONFIG['do_vad'],\n",
        "    do_enhance=CONFIG['do_enhance'],\n",
        "    similarity_threshold=CONFIG['similarity_threshold'],\n",
        "    playlist_mode=CONFIG['playlist_mode'],\n",
        ")\n",
        "results = pipeline.process(\n",
        "    youtube_url=CONFIG['youtube_url'],\n",
        "    ref_audio_path=ref_audio_path,\n",
        "    language=CONFIG['language'],\n",
        ")\n",
        "print('✅ done')\n"
      ],
      "id": "npU3D1uwW6jd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DtrTagFW6jd"
      },
      "source": [
        "## 6) 双GPU并行（可选，多任务时有效）\n",
        "说明：单个视频的同一条流水线很难高效吃满2块GPU。\n",
        "这个cell用于**多个URL并行**，每个进程绑定一张GPU。\n"
      ],
      "id": "9DtrTagFW6jd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zy79KsYTW6jd"
      },
      "outputs": [],
      "source": [
        "import os, subprocess, torch\n",
        "URLS = []  # 例如填2个视频链接，才能明显利用2块GPU\n",
        "if torch.cuda.device_count() < 2:\n",
        "    print('当前不足2块GPU，跳过')\n",
        "elif not URLS:\n",
        "    print('请先填 URLS 再运行')\n",
        "else:\n",
        "    procs=[]\n",
        "    for i,u in enumerate(URLS):\n",
        "        gpu=i%2\n",
        "        env=os.environ.copy()\n",
        "        env['CUDA_VISIBLE_DEVICES']=str(gpu)\n",
        "        cmd=[\n",
        "          'python','main.py',\n",
        "          '--youtube_url',u,\n",
        "          '--ref_audio',ref_audio_path,\n",
        "          '--output_dir',f'./output_gpu{gpu}_{i}',\n",
        "          '--language',CONFIG['language'],\n",
        "          '--max_speakers',str(CONFIG['max_speakers']),\n",
        "          '--whisper_model',CONFIG['whisper_model'],\n",
        "          '--playlist_mode',CONFIG['playlist_mode'],\n",
        "          '--no_separation'\n",
        "        ]\n",
        "        procs.append(subprocess.Popen(cmd, env=env))\n",
        "    for p in procs:\n",
        "        p.wait()\n",
        "    print('✅ dual-gpu batch done')\n"
      ],
      "id": "Zy79KsYTW6jd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpjtCLlMW6jd"
      },
      "source": [
        "## 7) 查看输出\n"
      ],
      "id": "QpjtCLlMW6jd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlBJV74MW6jd"
      },
      "outputs": [],
      "source": [
        "import glob, os\n",
        "for f in sorted(glob.glob('./output/*.srt') + glob.glob('./output/*.json')):\n",
        "    print('-', f)\n"
      ],
      "id": "mlBJV74MW6jd"
    }
  ]
}