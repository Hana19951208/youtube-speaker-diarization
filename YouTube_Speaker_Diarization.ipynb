{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnr-hAbZRxR4"
      },
      "source": [
        "# YouTube Speaker Diarization Pipeline\n",
        "\n",
        "This notebook provides an end-to-end pipeline for:\n",
        "1. Downloading audio from YouTube videos\n",
        "2. Transcribing speech using WhisperX\n",
        "3. Performing speaker diarization using PyAnnote\n",
        "4. Identifying target speakers using reference audio\n",
        "5. Generating SRT subtitles with speaker labels\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "### 1. Configure HuggingFace Token\n",
        "You need a HuggingFace token to access PyAnnote's speaker diarization model.\n",
        "\n",
        "1. Go to https://huggingface.co/settings/tokens\n",
        "2. Create a new token with 'read' access\n",
        "3. Accept the model license at https://huggingface.co/pyannote/speaker-diarization-3.1\n",
        "4. Enter your token below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jtucD6dRxR6",
        "outputId": "a9f2d060-044f-46f9-8162-c9b72ee146d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF_TOKEN set: True\n"
          ]
        }
      ],
      "source": [
        "# Set your HuggingFace token here\n",
        "HF_TOKEN = \"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\"  # <-- Paste your HF token here\n",
        "\n",
        "# Set environment variable\n",
        "import os\n",
        "os.environ['HF_TOKEN'] = HF_TOKEN\n",
        "\n",
        "print(f\"HF_TOKEN set: {bool(HF_TOKEN)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG3mSrKQRxR7"
      },
      "source": [
        "### 2. Install Dependencies\n",
        "Run the cell below to install all required packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-owA5qWRxR7",
        "outputId": "a09d4928-e51e-4b6c-f976-b4ef9002ed50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.1/182.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q torch torchaudio\n",
        "!pip install -q yt-dlp ffmpeg-python pydub\n",
        "!pip install -q demucs\n",
        "!pip install -q whisperx\n",
        "!pip install -q pyannote.audio\n",
        "!pip install -q speechbrain scikit-learn\n",
        "\n",
        "print(\"Dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WngPKHfaRxR7"
      },
      "source": [
        "### 3. Upload Reference Audio\n",
        "Upload a reference audio file of the target speaker you want to identify:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0vZTfVRRxR8"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload a reference audio file (WAV or MP3) of the target speaker:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "ref_audio_path = list(uploaded.keys())[0]\n",
        "print(f\"Reference audio uploaded: {ref_audio_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeaYidZXRxR8"
      },
      "source": [
        "## Pipeline Configuration\n",
        "\n",
        "Configure the pipeline parameters below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugB7zy08RxR8"
      },
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CONFIG = {\n",
        "    # YouTube URL to process\n",
        "    \"youtube_url\": \"https://www.youtube.com/watch?v=Zs8jUFaqtCI&list=PLCecIXiOoaWnlFxxe4eWa1a7EJ-BMXHzr\",  # <-- Paste YouTube URL here\n",
        "\n",
        "    # Language (set to None for auto-detect)\n",
        "    \"language\": None,  # e.g., \"en\", \"zh\", \"ja\", etc.\n",
        "\n",
        "    # Maximum number of speakers\n",
        "    \"max_speakers\": 3,\n",
        "\n",
        "    # WhisperX model size\n",
        "    \"whisper_model\": \"large-v3\",  # Options: tiny, base, small, medium, large-v1, large-v2, large-v3\n",
        "\n",
        "    # Processing options\n",
        "    \"do_separation\": True,  # Perform vocal separation\n",
        "    \"do_vad\": False,  # Apply voice activity detection\n",
        "    \"do_enhance\": False,  # Apply audio enhancement\n",
        "\n",
        "    # Speaker matching threshold\n",
        "    \"similarity_threshold\": 0.25,\n",
        "\n",
        "    # Output directory\n",
        "    \"output_dir\": \"./output\",\n",
        "}\n",
        "\n",
        "# Print configuration\n",
        "print(\"Pipeline Configuration:\")\n",
        "print(\"=\" * 60)\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjxpa0ZTRxR8"
      },
      "source": [
        "## Run the Pipeline\n",
        "\n",
        "Execute the cell below to run the complete pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Hana19951208/youtube-speaker-diarization.git\n",
        "%cd youtube-speaker-diarization\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vha1HhTkaEez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDT_QJfxRxR8"
      },
      "outputs": [],
      "source": [
        "# Initialize and run pipeline\n",
        "from pipeline import YouTubeSpeakerPipeline\n",
        "\n",
        "pipeline = YouTubeSpeakerPipeline(\n",
        "    hf_token=HF_TOKEN,\n",
        "    output_dir=CONFIG[\"output_dir\"],\n",
        "    whisper_model=CONFIG[\"whisper_model\"],\n",
        "    max_speakers=CONFIG[\"max_speakers\"],\n",
        "    do_separation=CONFIG[\"do_separation\"],\n",
        "    do_vad=CONFIG[\"do_vad\"],\n",
        "    do_enhance=CONFIG[\"do_enhance\"],\n",
        "    similarity_threshold=CONFIG[\"similarity_threshold\"],\n",
        ")\n",
        "\n",
        "results = pipeline.process(\n",
        "    youtube_url=CONFIG[\"youtube_url\"],\n",
        "    ref_audio_path=ref_audio_path,\n",
        "    language=CONFIG[\"language\"],\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PROCESSING COMPLETE!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjheewQSRxR9"
      },
      "source": [
        "## View Results\n",
        "\n",
        "### Download Output Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX-mKzTFRxR9"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Find output files\n",
        "output_files = [\n",
        "    os.path.join(CONFIG[\"output_dir\"], f)\n",
        "    for f in os.listdir(CONFIG[\"output_dir\"])\n",
        "    if f.endswith((\".srt\", \".json\"))\n",
        "]\n",
        "\n",
        "print(\"Output files available for download:\")\n",
        "for f in output_files:\n",
        "    print(f\"  - {os.path.basename(f)}\")\n",
        "\n",
        "# Download all files\n",
        "for f in output_files:\n",
        "    files.download(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXZsZpTbRxR9"
      },
      "source": [
        "### Preview SRT Content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_WcWqRLRxR9"
      },
      "outputs": [],
      "source": [
        "# Find and display the SRT file\n",
        "srt_files = [f for f in output_files if f.endswith('.srt')]\n",
        "\n",
        "if srt_files:\n",
        "    with open(srt_files[0], 'r', encoding='utf-8') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    print(\"SRT Preview (first 3000 characters):\")\n",
        "    print(\"=\" * 60)\n",
        "    print(content[:3000])\n",
        "    if len(content) > 3000:\n",
        "        print(\"\\n... (truncated)\")\n",
        "else:\n",
        "    print(\"No SRT file found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHPMEvAoRxR9"
      },
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "1. **CUDA Out of Memory**: Try using a smaller WhisperX model (e.g., `medium` instead of `large-v3`)\n",
        "2. **HF_TOKEN Error**: Make sure you've accepted the PyAnnote model license and set your token\n",
        "3. **FFmpeg Error**: Make sure FFmpeg is installed: `!apt-get install ffmpeg`\n",
        "4. **YouTube Download Error**: Some videos may be blocked or require authentication"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}